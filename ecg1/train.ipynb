{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'util'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-f65a739d8fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mMAX_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'util'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import sys             #chjoo added on Jul 28-2020\n",
    "\n",
    "import network\n",
    "import load\n",
    "import util\n",
    "\n",
    "MAX_EPOCHS = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_save_dir(dirname, experiment_name):\n",
    "    start_time = str(int(time.time())) + '-' + str(random.randrange(1000))\n",
    "    save_dir = os.path.join(dirname, experiment_name, start_time)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    return save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_for_saving(save_dir):\n",
    "    return os.path.join(save_dir,\n",
    "            \"{val_loss:.3f}-{val_acc:.3f}-{epoch:03d}-{loss:.3f}-{acc:.3f}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, params):\n",
    "    print(sys.argv[1:])\n",
    "    print(\"Loading training set...\")\n",
    "    train = load.load_dataset(params['train'])\n",
    "    print(\"Loading dev set...\")\n",
    "    dev = load.load_dataset(params['dev'])\n",
    "    print(\"Building preprocessor...\")\n",
    "    preproc = load.Preproc(*train)\n",
    "    print(\"Training size: \" + str(len(train[0])) + \" examples.\")\n",
    "    print(\"Dev size: \" + str(len(dev[0])) + \" examples.\")\n",
    "\n",
    "\n",
    "    save_dir = make_save_dir(params['save_dir'], args.experiment)\n",
    "\n",
    "    util.save(preproc, save_dir)\n",
    "\n",
    "    params.update({\n",
    "        \"input_shape\": [None, 1],\n",
    "        \"num_categories\": len(preproc.classes)\n",
    "    })\n",
    "\n",
    "    model = network.build_network(**params)\n",
    "\n",
    "    stopping = keras.callbacks.EarlyStopping(patience=8)\n",
    "\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.1,\n",
    "        patience=2,\n",
    "        min_lr=params[\"learning_rate\"] * 0.001)\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=get_filename_for_saving(save_dir),\n",
    "        save_best_only=False)\n",
    "\n",
    "    batch_size = params.get(\"batch_size\", 32)\n",
    "\n",
    "    if params.get(\"generator\", False):\n",
    "        train_gen = load.data_generator(batch_size, preproc, *train)\n",
    "        dev_gen = load.data_generator(batch_size, preproc, *dev)\n",
    "        model.fit_generator(\n",
    "            train_gen,\n",
    "            steps_per_epoch=int(len(train[0]) / batch_size),\n",
    "            epochs=MAX_EPOCHS,\n",
    "            validation_data=dev_gen,\n",
    "            validation_steps=int(len(dev[0]) / batch_size),\n",
    "            callbacks=[checkpointer, reduce_lr, stopping])\n",
    "    else:\n",
    "        train_x, train_y = preproc.process(*train)\n",
    "        dev_x, dev_y = preproc.process(*dev)\n",
    "        model.fit(\n",
    "            train_x, train_y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=MAX_EPOCHS,\n",
    "            validation_data=(dev_x, dev_y),\n",
    "            callbacks=[checkpointer, reduce_lr, stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--experiment EXPERIMENT] config_file\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"config_file\", help=\"path to config file\")\n",
    "    parser.add_argument(\"--experiment\", \"-e\", help=\"tag with experiment name\",\n",
    "                        default=\"default\")\n",
    "    args = parser.parse_args()\n",
    "    print(\"args.config_file = {}\".format(args.config_file))\n",
    "    params = json.load(open(args.config_file, 'r'))\n",
    "    train(args, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
